{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a8ea7e",
   "metadata": {},
   "source": [
    "# Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9690a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src import config\n",
    "from src import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622716fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global cache for the model (so we don't reload it 100 times)\n",
    "_MODEL = None\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"\n",
    "    Loads the trained model from the models/ directory.\n",
    "    Uses a global variable to cache it (Singleton pattern).\n",
    "    \"\"\"\n",
    "    global _MODEL\n",
    "    \n",
    "    if _MODEL is None:\n",
    "        model_path = os.path.join(\"..\", \"models\", f\"{config.MODEL_NAME}_v1.pkl\")\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"‚ùå Model not found at {model_path}. Run src/train.py first!\")\n",
    "            \n",
    "        print(f\"Loading model from {model_path}...\")\n",
    "        _MODEL = joblib.load(model_path)\n",
    "        \n",
    "    return _MODEL\n",
    "\n",
    "def make_prediction(input_data):\n",
    "    \"\"\"\n",
    "    Main entry point for inference.\n",
    "    Args:\n",
    "        input_data (dict or pd.DataFrame): Raw input data.\n",
    "    Returns:\n",
    "        dict: {'prediction': int, 'probability': float, 'status': str}\n",
    "    \"\"\"\n",
    "    # 1. Convert Dictionary to DataFrame (if needed)\n",
    "    if isinstance(input_data, dict):\n",
    "        df = pd.DataFrame([input_data])\n",
    "    else:\n",
    "        df = input_data.copy()\n",
    "        \n",
    "    # 2. Preprocessing (Must match training!)\n",
    "    # NOTE: In a real complex project, we would load a saved 'pipeline.pkl' here.\n",
    "    # For this template, we apply the stateless cleaning functions.\n",
    "    df = pp.clean_column_names(df)\n",
    "    \n",
    "    # 3. Load Model\n",
    "    model = load_model()\n",
    "    \n",
    "    # 4. Predict\n",
    "    # Ensure columns match model expectation\n",
    "    try:\n",
    "        prediction = model.predict(df)[0]\n",
    "        \n",
    "        # Get probability if supported (for \"Risk Score\")\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            probability = model.predict_proba(df)[0][1] # Probability of Class 1 (Default)\n",
    "        else:\n",
    "            probability = None\n",
    "            \n",
    "        return {\n",
    "            \"prediction\": int(prediction),\n",
    "            \"probability\": float(probability) if probability else 0.0,\n",
    "            \"status\": \"Success\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"prediction\": None,\n",
    "            \"error\": str(e),\n",
    "            \"status\": \"Failed\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Libraries loaded. Inference functions defined. Ready to test inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean data just to get a sample row\n",
    "df = pd.read_csv(f\"../{config.PROCESSED_DATA_PATH}\")\n",
    "\n",
    "# Pick a random row (e.g., row #100)\n",
    "sample_row = df.iloc[100]\n",
    "print(\"--- Sample Input Data ---\")\n",
    "print(sample_row)\n",
    "\n",
    "# Separate Target (We don't send the answer to the model!)\n",
    "ground_truth = sample_row[config.TARGET_COLUMN]\n",
    "input_data = sample_row.drop(config.TARGET_COLUMN).to_dict()\n",
    "\n",
    "print(\"\\n--- Input Payload (JSON-like) ---\")\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è≥ Calling make_prediction()...\")\n",
    "\n",
    "# START TIMER\n",
    "start_time = time.time()\n",
    "\n",
    "# CALL THE FUNCTION\n",
    "result = make_prediction(input_data)\n",
    "\n",
    "# STOP TIMER\n",
    "end_time = time.time()\n",
    "latency = (end_time - start_time) * 1000 # Convert to ms\n",
    "\n",
    "print(f\"\\n‚úÖ Prediction Result: {result}\")\n",
    "print(f\"‚è±Ô∏è Latency: {latency:.2f} ms\")\n",
    "print(f\"üéØ Actual Value (Ground Truth): {ground_truth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"running batch stress test...\")\n",
    "success_count = 0\n",
    "errors = []\n",
    "\n",
    "# Take 100 random samples\n",
    "batch = df.sample(100).drop(columns=[config.TARGET_COLUMN]).to_dict(orient='records')\n",
    "\n",
    "for i, record in enumerate(batch):\n",
    "    try:\n",
    "        res = make_prediction(record)\n",
    "        if res['status'] == 'Success':\n",
    "            success_count += 1\n",
    "    except Exception as e:\n",
    "        errors.append(e)\n",
    "\n",
    "print(f\"Batch Test Complete: {success_count}/100 successful.\")\n",
    "if errors:\n",
    "    print(f\"First Error: {errors[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
